{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Regime Test\n",
    "\n",
    "The purpose of this notebook is to experiment with plotting the fidelities of different random codes at different amounts of loss and dephasing noise and compare their performances. This helps us determine whether there is any sort of pattern or way to determine what types of codes or what parameters for codes are better for what regions.\n",
    "\n",
    "This is the first notebook to experiment with using multiprocessing to reduce computation times. As long as the same computation isn't being run for a non-random code, that code should be thread-safe already. However, for random codes, running the same computation is necessary because the codes aren't deterministically made from their parameters, so that code was made threadsafe with the use of a lock. The way multiprocessing is used in this notebook should be safe.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess\n",
    "import qutip as qt\n",
    "from src import code_simulator, code, noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_noise_values = np.geomspace(0.001, 0.1, 11)\n",
    "# dephasing_noise_values = np.geomspace(0.001, 0.1, 11)\n",
    "loss_noise_values = np.linspace(0, 0.1, 11)\n",
    "dephasing_noise_values = np.linspace(0, 0.1, 11)\n",
    "rotation_symmetries = [2, 3, 4, 5]\n",
    "average_photon_numbers = range(1, 5)\n",
    "number_of_random_code_trials = 40"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fidelities of Binomial Code\n",
    "\n",
    "Getting the code and noise channels isn't done asynchronously because they may not be generated yet and they have unprotected file IO. After the following cell though, getting noise and binomial codes can be done asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "code_parameters = [rotation_symmetries, average_photon_numbers]\n",
    "noise_parameters = [loss_noise_values, dephasing_noise_values]\n",
    "\n",
    "def make_binomial_code(rotation_symmetry, average_photon_number):\n",
    "\tdimension = (average_photon_number + 2) * rotation_symmetry\n",
    "\treturn code.get_binomial_code(rotation_symmetry, average_photon_number, dimension)\n",
    "def make_combined_loss_channel(loss_noise_value, dephasing_noise_value, rotation_symmetry, average_photon_number):\n",
    "\tdimension = (average_photon_number + 2) * rotation_symmetry\n",
    "\treturn noise.Noise(dimension, [(\"dephasing\", dephasing_noise_value), (\"loss\", loss_noise_value)])\n",
    "binomial_fidelities = code_simulator.run_parameter_sweep_for_optimal_fidelities(code_parameters, noise_parameters, make_binomial_code, make_combined_loss_channel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Code Optimal Fidelities in Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_binomial_fidelities_per_region = np.max(binomial_fidelities.reshape((len(loss_noise_values), len(dephasing_noise_values), -1)), -1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(1 - best_binomial_fidelities_per_region, origin=\"lower\")\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(len(loss_noise_values)), loss_noise_values)\n",
    "ax.set_xticks(range(len(dephasing_noise_values)), dephasing_noise_values)\n",
    "plt.title(\"1 - $F_\\\\mathcal{E}$ for Binomial Codes\\nfor Each Combined Noise Channel\")\n",
    "plt.ylabel(\"$\\\\kappa_l$\")\n",
    "plt.xlabel(\"$\\\\kappa_\\\\phi$\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Binomial Code Parameters for Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = [[None for _ in dephasing_noise_values] for _ in loss_noise_values]\n",
    "for i, loss_noise_value in enumerate(loss_noise_values):\n",
    "\tfor j, dephasing_noise_value in enumerate(dephasing_noise_values):\n",
    "\t\tfidelities_in_region = binomial_fidelities[i,j]\n",
    "\t\tmaximizing_indices = np.unravel_index(fidelities_in_region.argmax(), fidelities_in_region.shape)\n",
    "\t\tbest_parameters[i][j] = (rotation_symmetries[maximizing_indices[0]], average_photon_numbers[maximizing_indices[1]])\n",
    "unique_best_parameters = list(set([parameter for parameter_list in best_parameters for parameter in parameter_list]))\n",
    "parameter_to_data = {value: index for index, value in enumerate(unique_best_parameters)}\n",
    "image_data = np.array([[parameter_to_data[parameter] for parameter in sublist] for sublist in best_parameters])\n",
    "\n",
    "plt.figure()\n",
    "imshow = plt.imshow(image_data, origin=\"lower\", interpolation=\"none\", cmap=\"gist_rainbow\")\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(len(loss_noise_values)), loss_noise_values)\n",
    "ax.set_xticks(range(len(dephasing_noise_values)), dephasing_noise_values)\n",
    "plt.title(\"Best Binomial Code Parameters\\nfor Each Combined Noise Channel\")\n",
    "plt.ylabel(\"$\\\\kappa_l$\")\n",
    "plt.xlabel(\"$\\\\kappa_\\\\phi$\")\n",
    "used_colors = [imshow.cmap(imshow.norm(value)) for value in range(len(unique_best_parameters))]\n",
    "patches = [matplotlib.patches.Patch(color=used_colors[i], label=f\"$\\\\left(N, \\\\langle\\\\hat n\\\\rangle\\\\right)$ = {unique_best_parameters[i]}\") for i in range(len(unique_best_parameters))]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_image_data = [[rotation_symmetry for rotation_symmetry, _ in sublist] for sublist in best_parameters]\n",
    "unique_good_rotation_symmetries = list(set([rotation_symmetry for sublist in stripped_image_data for rotation_symmetry in sublist]))\n",
    "\n",
    "plt.figure()\n",
    "imshow = plt.imshow(stripped_image_data, origin=\"lower\", interpolation=\"none\", cmap=\"gist_rainbow\")\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(len(loss_noise_values)), loss_noise_values)\n",
    "ax.set_xticks(range(len(dephasing_noise_values)), dephasing_noise_values)\n",
    "plt.title(\"Best Binomial Code Rotation Symmetry\\nfor Each Combined Noise Channel\")\n",
    "plt.ylabel(\"$\\\\kappa_l$\")\n",
    "plt.xlabel(\"$\\\\kappa_\\\\phi$\")\n",
    "used_colors = [imshow.cmap(imshow.norm(rotation_symmetry)) for rotation_symmetry in unique_good_rotation_symmetries]\n",
    "patches = [matplotlib.patches.Patch(color=used_colors[i], label=f\"$N = {unique_good_rotation_symmetries[i]}$\") for i in range(len(unique_good_rotation_symmetries))]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Fidelities for Two-Expanded Haar Random Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def run_random_code_data_generation_for(loss_noise_value, dephasing_noise_value, rotation_symmetry, average_photon_number):\n",
    "\tdimension = (average_photon_number + 2) * rotation_symmetry\n",
    "\tcombined_noise = noise.Noise(dimension, [(\"dephasing\", dephasing_noise_value), (\"loss\", loss_noise_value)])\n",
    "\trandom_code = code.make_two_expanded_haar_random_code(rotation_symmetry, average_photon_number, dimension)\n",
    "\treturn code_simulator.get_fidelity_of(random_code, combined_noise, True, lock)\n",
    "\n",
    "async_processes = []\n",
    "for i, loss_noise_value in enumerate(loss_noise_values):\n",
    "\tfor j, dephasing_noise_value in enumerate(dephasing_noise_values):\n",
    "\t\tfor k, rotation_symmetry in enumerate(rotation_symmetries):\n",
    "\t\t\tfor l, average_photon_number in enumerate(average_photon_numbers):\n",
    "\t\t\t\tfor m in range(number_of_random_code_trials):\n",
    "\t\t\t\t\tasync_processes.append(pool.apply_async(run_random_code_data_generation_for, (loss_noise_value, dephasing_noise_value, rotation_symmetry, average_photon_number)))\n",
    "[process.get() for process in async_processes];"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Best Stored Random Code Fidelities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_best_random_fidelity(loss_noise_value, dephasing_noise_value, rotation_symmetry, average_photon_number):\n",
    "\tdimension = (average_photon_number + 2) * rotation_symmetry\n",
    "\tcombined_noise = noise.Noise(dimension, [(\"dephasing\", dephasing_noise_value), (\"loss\", loss_noise_value)])\n",
    "\tcode_name = f\"two-expanded-haar-random-{rotation_symmetry},{average_photon_number},{dimension}\"\n",
    "\treturn code_simulator.get_known_fidelity_for(code_name, True, combined_noise, True)\n",
    "\n",
    "random_fidelity_processes = np.zeros((len(loss_noise_values), len(dephasing_noise_values), len(rotation_symmetries), len(average_photon_numbers))).tolist()\n",
    "for i, loss_noise_value in enumerate(loss_noise_values):\n",
    "\tfor j, dephasing_noise_value in enumerate(dephasing_noise_values):\n",
    "\t\tfor k, rotation_symmetry in enumerate(rotation_symmetries):\n",
    "\t\t\tfor l, average_photon_number in enumerate(average_photon_numbers):\n",
    "\t\t\t\trandom_fidelity_processes[i][j][k][l] = pool.apply_async(get_best_random_fidelity, (loss_noise_value, dephasing_noise_value, rotation_symmetry, average_photon_number))\n",
    "random_fidelities = np.empty((len(loss_noise_values), len(dephasing_noise_values), len(rotation_symmetries), len(average_photon_numbers)))\n",
    "for i in range(len(loss_noise_values)):\n",
    "\tfor j in range(len(dephasing_noise_values)):\n",
    "\t\tfor k in range(len(rotation_symmetries)):\n",
    "\t\t\tfor l in range(len(average_photon_numbers)):\n",
    "\t\t\t\trandom_fidelities[i,j,k,l] = random_fidelity_processes[i][j][k][l].get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Code Optimal Fidelities in Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_fidelities_per_region = np.max(random_fidelities.reshape((len(loss_noise_values), len(dephasing_noise_values), -1)), -1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(1 - best_random_fidelities_per_region, origin=\"lower\")\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(len(loss_noise_values)), loss_noise_values)\n",
    "ax.set_xticks(range(len(dephasing_noise_values)), dephasing_noise_values)\n",
    "plt.title(\"1 - $F_\\\\mathcal{E}$ for Random Codes\\nfor Each Combined Noise Channel\")\n",
    "plt.ylabel(\"$\\\\kappa_l$\")\n",
    "plt.xlabel(\"$\\\\kappa_\\\\phi$\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Code in Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_difference = best_random_fidelities_per_region - best_binomial_fidelities_per_region\n",
    "\n",
    "cmap = plt.get_cmap(\"RdBu\")\n",
    "most_extreme_fidelity_difference = max(np.max(fidelity_difference), np.max(-fidelity_difference))\n",
    "normalizer = matplotlib.colors.Normalize(-most_extreme_fidelity_difference, most_extreme_fidelity_difference)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(fidelity_difference, origin=\"lower\", cmap=cmap, norm=normalizer)\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(len(loss_noise_values)), loss_noise_values)\n",
    "ax.set_xticks(range(len(dephasing_noise_values)), dephasing_noise_values)\n",
    "plt.title(\"Difference Between Best Random and Binomial Fidelities\\nfor Each Combined Noise Channel\")\n",
    "plt.ylabel(\"$\\\\kappa_l$\")\n",
    "plt.xlabel(\"$\\\\kappa_\\\\phi$\")\n",
    "plt.colorbar(matplotlib.cm.ScalarMappable(norm=normalizer, cmap=cmap), ax=plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
